{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5ce4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from datetime import datetime\n",
    "import difflib\n",
    "import json\n",
    "import requests\n",
    "import stanza\n",
    "\n",
    "STANZA_PIPELINE = stanza.Pipeline('en',\n",
    "                                  processors='tokenize',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f3d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/w/api.php'\n",
    "#title = \"Karen_Sp√§rck_Jones_Award\"\n",
    "title = \"2008_United_States_presidential_election\"\n",
    "rev_map = collections.defaultdict(list)\n",
    "for title in [\n",
    "  #title,\n",
    "              f'Talk:{title}',]:\n",
    "  print(title)\n",
    "  rvstart = None\n",
    "  while True:\n",
    "    params = {\n",
    "    'action':\"query\",\n",
    "    'prop':\"revisions\",\n",
    "    'titles':title,\n",
    "    'rvlimit': 500,\n",
    "    \"rvprop\":\"timestamp|user|comment|ids|content\",\n",
    "    \"rvdir\": \"newer\",\n",
    "    \"format\":\"json\"\n",
    "    }\n",
    "    if rvstart is not None:\n",
    "      params['rvstart'] = rvstart\n",
    "    response = requests.get(url, params=params)\n",
    "    submissions = response.json()\n",
    "    if 'batchcomplete' not in submissions:\n",
    "      rvstart = submissions['continue']['rvcontinue'].split('|')[0]\n",
    "    for i in list(submissions['query']['pages'].values())[0]['revisions']:\n",
    "      p = {\"title\": title}\n",
    "      p.update(i)\n",
    "      rev_map[datetime.fromisoformat(i['timestamp'][:-1]).timestamp()].append(p)\n",
    "    print(datetime.fromtimestamp(max(rev_map.keys())))\n",
    "    if 'batchcomplete' in submissions:\n",
    "      break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a713e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=0\n",
    "\n",
    "# for t in sorted(rev_map.keys()):\n",
    "#   for k, v in rev_map[t][0].items():\n",
    "#     if k in ['*', 'contentformat', 'contentmodel']:\n",
    "#       continue\n",
    "#     print(f'{k}: {v}\\t', end=\"\")\n",
    "#   print()\n",
    "#   print()\n",
    "#   i += 1\n",
    "#   if i == 1000:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd586e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_bank = collections.defaultdict(list)\n",
    "\n",
    "for k,v in rev_map.items():\n",
    "  print(k)\n",
    "  vals = v[0]\n",
    "  tokenized = STANZA_PIPELINE(vals['*'])\n",
    "  title = vals['title']\n",
    "  sentence_indices= []\n",
    "  for sentence in tokenized.sentences:\n",
    "    if sentence.text in sentence_bank[title]:\n",
    "      sentence_indices.append(sentence_bank[title].index(sentence.text))\n",
    "    else:\n",
    "      sentence_indices.append(len(sentence_bank[title]))\n",
    "      sentence_bank[title].append(sentence.text)\n",
    "  print(len(sentence_indices), len(set(sentence_indices)), len(sentence_bank[title]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be243f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = 0\n",
    "\n",
    "for k in reversed(sorted(rev_map.keys())):\n",
    "  v = rev_map[k]\n",
    "  for i in v:\n",
    "    if 'edit' in json.dumps(i) and 'request' in json.dumps(i):\n",
    "      print(i)\n",
    "      print()\n",
    "      flag = 1\n",
    "      break\n",
    "  if flag:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167de3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywikibot as pw\n",
    "import re\n",
    "site = pw.Site('en', 'wikipedia')\n",
    "edit_request_count = 0\n",
    "for page in site.allpages(prefix='2004_United_States_presidential_election/', namespace='Talk'):\n",
    "    print(page.title())\n",
    "    edit_request_count += len(re.findall('Edit.request', page.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44563d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_request_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df9ac9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
